{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bi-horn/CNN_XRay/blob/main/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdb_RABbkdWs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models.inception import InceptionOutputs\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing\n",
        "def data_preprocess(data_path, sample_ratio):\n",
        "  # Create data transforms\n",
        "  data_transforms = transforms.Compose([\n",
        "    #standard measures if you want to use e.g. ResNet18\n",
        "    transforms.Resize((224, 224)), #Consistent Formatting: Ensure uniform size and tensor format for inputs\n",
        "    transforms.RandomHorizontalFlip(), #Data Augmentation: Enhance dataset diversity with random transformations\n",
        "    transforms.ToTensor(), #datset to 4D tensor (# of images, height, width, channels)\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) #Standardization: Normalize pixel values for consistent convergence\n",
        "\n",
        "  # Get dataset from folder and apply data transforms\n",
        "  dataset = datasets.ImageFolder(root = \"{}data\".format(data_path), transform = data_transforms)\n",
        "\n",
        "\n",
        "  # Get a sample of the data randomly\n",
        "  num_samples = int(len(dataset) * sample_ratio)\n",
        "  indices = np.random.choice(range(len(dataset)), num_samples, replace = False)\n",
        "\n",
        "  # Split the data into training, test, and validation sets\n",
        "  train_size = int(0.7 * num_samples)\n",
        "  test_size = int(0.2 * num_samples)\n",
        "  val_size = num_samples - train_size - test_size\n",
        "\n",
        "  train_indices = indices[ : train_size]\n",
        "  test_indices = indices[train_size : train_size + test_size]\n",
        "  val_indices = indices[train_size + test_size : ]\n",
        "\n",
        "  #Load the dataset into a format that PyTorch can use, such as a torch.utils.data.Dataset.\n",
        "  # Create random training, test, and validation datasets\n",
        "\n",
        "  samples = [torch.utils.data.sampler.SubsetRandomSampler(i) for i in [train_indices, test_indices, val_indices]]\n",
        "\n",
        "  train_loader = DataLoader(dataset, batch_size = batch_size, sampler = samples[0], num_workers = 4, pin_memory = True)\n",
        "  test_loader = DataLoader(dataset, batch_size = batch_size, sampler = samples[1], num_workers = 4, pin_memory = True)\n",
        "  val_loader = DataLoader(dataset, batch_size = batch_size, sampler = samples[2], num_workers = 4, pin_memory = True)\n",
        "\n",
        "  return dataset, train_loader, train_indices, test_loader, test_indices, val_loader, val_indices"
      ],
      "metadata": {
        "id": "1XC7GPr1kw4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the metrics after training\n",
        "def save_metrics(loss, accuracy, validation_loss, validation_accuracy, model):\n",
        "    np.save(\"{}{}_train_loss.npy\".format(data_path, model), loss)\n",
        "    np.save(\"{}{}_train_accuracy.npy\".format(data_path, model), accuracy)\n",
        "    np.save(\"{}{}_validation_loss.npy\".format(data_path, model), validation_loss)\n",
        "    np.save(\"{}{}_validation_accuracy.npy\".format(data_path, model), validation_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "hGfFjFJzidet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, model_name, num_epochs):\n",
        "\n",
        "  start1_time = time.time()\n",
        "\n",
        "  #Create tracking variables\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  true = []\n",
        "  pred = []\n",
        "  v_accuracies = []\n",
        "  v_losses = []\n",
        "\n",
        "\n",
        "  #for loop through epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0\n",
        "    start_time = time.time() #set the timer\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar: #Progress Bar Initialization\n",
        "      #Training Loop\n",
        "      for X_train, y_train in train_loader: #Iterates through the training dataset using the train_loader; each iteration processes a batch of input data and their corresponding labels\n",
        "        #Moves the input data and labels to the computing device (e.g., GPU)\n",
        "        X_train = X_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "\n",
        "        outputs = model(X_train)\n",
        "        #Prediction and Loss Calculation\n",
        "        #Add up correct predictions\n",
        "        _, preds = torch.max(outputs.logits if isinstance(outputs, InceptionOutputs) else outputs, dim = 1) #logits = raw scores produced by the final layer of the Inception model before applying a softmax activation function\n",
        "        #Calculates the loss between the model predictions and the actual labels using the specified loss criterion\n",
        "        loss = criterion(outputs.logits if isinstance(outputs, InceptionOutputs) else outputs, y_train)\n",
        "\n",
        "        #Backpropagation and Optimization\n",
        "        optimizer.zero_grad() #Resets the gradients of the optimizer to zero\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #Metrics Calculation\n",
        "        train_loss = loss.item() * X_train.size(0) #Computes the loss for the current batch (train_loss) and accumulates it over all batches\n",
        "        #how many correct from that batch\n",
        "        train_accuracy += torch.sum(preds == y_train.data)\n",
        "        #Data Aggregation\n",
        "        pred.extend(preds.cpu().numpy()) #Extends lists (pred and true) with the predictions and true labels for the current batch, respectively\n",
        "        true.extend(y_train.cpu().numpy())\n",
        "\n",
        "        #print results\n",
        "        pbar.set_postfix({'Accuracy': train_accuracy.item()/len(train_indices), 'Loss': train_loss/len(train_indices), 'Precision': precision_score(true, pred, average='macro'), 'Recall': recall_score(true, pred, average='macro'), 'F1 Score': f1_score(true, pred, average = 'macro')})\n",
        "        pbar.update()\n",
        "\n",
        "    #evaluate model for validation dataset\n",
        "    val_accuracy, val_loss, val_true, val_pred = evaluate_model(model, val_loader, val_indices, 'VALIDATION', criterion, data_path, model_name)\n",
        "\n",
        "    v_accuracies.append(val_accuracy)\n",
        "    v_losses.append(val_loss)\n",
        "    losses.append(train_loss/len(train_indices))\n",
        "    accuracies.append(train_accuracy.item()/len(train_indices))\n",
        "\n",
        "  save_metrics(losses, accuracies, v_losses, v_accuracies, model_name)\n",
        "\n",
        "  current_time = time.time()\n",
        "  total = current_time - start1_time\n",
        "  print(f'Training took: {total/60} minutes')\n",
        "\n",
        "  return losses, accuracies, v_accuracies, v_losses"
      ],
      "metadata": {
        "id": "E4NrIuYyA6G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, data_size, dtype, criterion, data_path, model_name):\n",
        "  _loss, _pred, _true, _accuracy = 0.0, [], [], []\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X_train, y_train in dataloader:\n",
        "      X_train = X_train.to(device)\n",
        "      y_train = y_train.to(device)\n",
        "\n",
        "      outputs = model(X_train)\n",
        "      loss = criterion(outputs, y_train)\n",
        "\n",
        "      _loss += loss.item() * X_train.size(0) #Accumulate the loss for the current sample\n",
        "      _, predicted = torch.max(outputs.data, 1) #Compute the predicted class indices for each element in the sample: find the indices of the maximum values along the second dimension of the output tensors\n",
        "      _pred.extend(predicted.cpu().numpy()) #Append the predicted class indices to the _pred list\n",
        "      _true.extend(y_train.cpu().numpy()) #Append the true class indices to the _true list\n",
        "\n",
        "  _loss /= len(data_size) #Calculate the average loss by dividing the total loss by the size of the dataset\n",
        "  _accuracy = accuracy_score(_true, _pred) #Compute the accuracy score by comparing the true labels with the predicted labels\n",
        "  #The average='macro' parameter calculates the score for each class independently and then averages them\n",
        "  _recall = recall_score(_true, _pred, average='macro') #Measures the ability of the classifier to identify all relevant instances\n",
        "  _precision = precision_score(_true, _pred, average='macro') #Measures the ability of the classifier not to flag a negative sample as positive\n",
        "  _fscore = f1_score(_true, _pred, average='macro') # F1 score = harmonic mean of precision and recall\n",
        "\n",
        "  print('{}: Accuracy: {:.4f} | Loss: {:.4f} | Recall: {:.4f} | Precision: {:.4f} | F-score: {:.4f}'.format(dtype, _accuracy, _loss, _recall, _precision, _fscore))\n",
        "  print(\"\")\n",
        "\n",
        "  return _accuracy, _loss, _true, _pred"
      ],
      "metadata": {
        "id": "Hni92VqElNov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#self-defined convolutional network\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #Two convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, 1)  # Input channels: 3, Output channels: 6, Kernel size: 5x5\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, 1)  # Input channels: 6, Output channels: 16, Kernel size: 5x5\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 53 * 53, 120)  # Input size: 16*53*53, Output size: 120\n",
        "        #53 * 53 because the input image size is 224x224 pixels, and each max-pooling operation with a 2x2 kernel and stride 2 reduces the dimensions by a factor of 2. After passing through two max-pooling layers, the height and width dimensions are reduced to approximately one-fourth of the original size, resulting in a feature map size of approximately 53x53.\n",
        "        self.fc2 = nn.Linear(120, 84)  # Input size: 120, Output size: 84\n",
        "        self.fc3 = nn.Linear(84, 2)  # Input size: 84, Output size: 2 (2 classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.conv1(X))\n",
        "        X = F.max_pool2d(X, 2, 2)  # Max pooling with 2x2 kernel and stride 2; dimensions of the feature map are reduced by a factor of 2 in both height and width\n",
        "        # Second convolutional layer\n",
        "        X = F.relu(self.conv2(X))\n",
        "        X = F.max_pool2d(X, 2, 2)  # Max pooling with 2x2 kernel and stride 2\n",
        "\n",
        "        # Flatten the feature map\n",
        "        X = X.view(-1, 16 * 53 * 53)  # Calculate the new size based on the dimensions of the feature map after the second convolutional layer\n",
        "\n",
        "        # Fully connected layers\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = self.fc3(X)\n",
        "\n",
        "        return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "SnsG-edOlYKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_curves(losses, accuracies, v_accuracies, v_losses, data_path, model_name):\n",
        "  #Plotting the Loss and Accuracy Curves\n",
        "\n",
        "  # Set global font size for labels\n",
        "  plt.rc('xtick', labelsize=12)    # Set x-axis label size to 12\n",
        "  plt.rc('ytick', labelsize=12)    # Set y-axis label size to 12\n",
        "  plt.rc('axes', labelsize=14)     # Set axes label size to 14\n",
        "  plt.rc('figure', titlesize=16)     # Set title size to 16\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "  fig.suptitle('Training and Validation Loss Curve - {}'.format(model_name))\n",
        "\n",
        "  y_step = 0.1\n",
        "  x_step = 2\n",
        "\n",
        "  ax1.plot(losses, label = \"Training Loss\", color='darkblue')\n",
        "  ax1.plot(v_losses, label = \"Validation Loss\", color='lightblue')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('Loss')\n",
        "  # Set the y-axis limits for the first subplot\n",
        "  ax1.set_ylim(-0.1, 1.1)\n",
        "  ax1.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax1.set_xticks(range(0, 20, x_step))\n",
        "  ax1.legend()\n",
        "\n",
        "  ax2.plot(accuracies, label = \"Training Accuracy\", color='darkblue')\n",
        "  ax2.plot(v_accuracies, label = \"Validation Accuracy\", color='lightblue')\n",
        "  ax2.set_xlabel('Epoch')\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.set_ylim(-0.1, 1.1)\n",
        "  ax2.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax2.set_xticks(range(0, 20, x_step))\n",
        "  ax2.legend(loc='lower right')\n",
        "\n",
        "\n",
        "  # Moving the legend outside the plot\n",
        "  #plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "\n",
        "  plt.savefig(\"{}{}_loss_accuracy.png\".format(data_path, model_name))  # Save the figure\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "EtPTVy3xyCMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Model on Test Set\n",
        "def plot_confusion_mat(_true, _pred, model_name, dataloader, dtype, data_path):\n",
        "    # calculate confusion matrix\n",
        "    cm = confusion_matrix(_true, _pred)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "\n",
        "    #Create ConfusionMatrixDisplay object with labels\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dataset.classes)\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix for {} dataset - {}\".format(dtype, model_name))\n",
        "\n",
        "    plt.savefig(\"{}{}_{}_confusion_mat.png\".format(data_path, model_name, dtype))  # Save the figure\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QpITnmWNyGPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates ROC plot and returns AUC using sklearn\n",
        "\n",
        "#y_true: true binary values\n",
        "# y_score: Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by “decision_function” on some classifiers).\n",
        "def generate_roc(y_true, y_score, data_path, model_name, pos_label = 1): #if y_true is in {-1, 1} or {0, 1}, pos_label is set to 1\n",
        "  #false positive rate (FPR) and true positive rate (TPR) for different threshold values.\n",
        "  fpr, tpr, _ = roc_curve(y_true, y_score, pos_label = pos_label)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  print(\"fpr:\", fpr)\n",
        "  print(\"tpr:\", tpr)\n",
        "  print(\"roc_auc:\", roc_auc)\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
        "  plt.plot([0, 1], [0, 1], \"k--\")\n",
        "  plt.xlim([0.0, 1.05])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.title(\"Receiver operating characteristic curve\")\n",
        "  plt.savefig(\"{}{}_ROC.png\".format(data_path, model_name))  # Save the figure\n",
        "  plt.show()\n",
        "\n",
        "  print(roc_auc)\n"
      ],
      "metadata": {
        "id": "544LkbvHUbU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_curves_comparison(losses, accuracies, v_accuracies, v_losses, losses_np, accuracies_np, v_accuracies_np, v_losses_np, data_path, model_name):\n",
        "  #Plotting the Loss and Accuracy Curves\n",
        "\n",
        "  # Set global font size for labels\n",
        "  plt.rc('xtick', labelsize=12)    # Set x-axis label size to 12\n",
        "  plt.rc('ytick', labelsize=12)    # Set y-axis label size to 12\n",
        "  plt.rc('axes', labelsize=14)     # Set axes label size to 14\n",
        "  plt.rc('figure', titlesize=16)     # Set title size to 16\n",
        "\n",
        "  fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "  fig.suptitle('Training and Validation Loss Curve Comparison\\n between pretrained and not pretrained {} model'.format(model_name))\n",
        "\n",
        "  y_step = 0.1\n",
        "  x_step = 2\n",
        "\n",
        "  ax1.plot(losses, label = \"Training Loss - pretrained\", color='darkblue')\n",
        "  ax1.plot(v_losses, label = \"Validation Loss - pretrained\", color='lightblue')\n",
        "  #ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('Loss')\n",
        "  # Set the y-axis limits for the first subplot\n",
        "  ax1.set_ylim(-0.1, 1.1)\n",
        "  ax1.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax1.set_xticks(range(0, 20, x_step))\n",
        "  ax1.legend()\n",
        "\n",
        "  ax2.plot(accuracies, label = \"Training Accuracy - pretrained\", color='darkblue')\n",
        "  ax2.plot(v_accuracies, label = \"Validation Accuracy - pretrained\", color='lightblue')\n",
        "  #ax2.set_xlabel('Epoch')\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.set_ylim(-0.1, 1.1)\n",
        "  ax2.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax2.set_xticks(range(0, 20, x_step))\n",
        "  ax2.legend(loc='lower right')\n",
        "\n",
        "  ax3.plot(losses_np, label = \"Training Loss\", color='red')\n",
        "  ax3.plot(v_losses_np, label = \"Validation Loss\", color='orange')\n",
        "  ax3.set_xlabel('Epoch')\n",
        "  ax3.set_ylabel('Loss')\n",
        "  # Set the y-axis limits for the first subplot\n",
        "  ax3.set_ylim(-0.1, 1.1)\n",
        "  ax3.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax3.set_xticks(range(0, 20, x_step))\n",
        "  ax3.legend()\n",
        "\n",
        "  ax4.plot(accuracies_np, label = \"Training Accuracy\", color='red')\n",
        "  ax4.plot(v_accuracies_np, label = \"Validation Accuracy\", color='orange')\n",
        "  ax4.set_xlabel('Epoch')\n",
        "  ax4.set_ylabel('Accuracy')\n",
        "  ax4.set_ylim(-0.1, 1.1)\n",
        "  ax4.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax4.set_xticks(range(0, 20, x_step))\n",
        "  ax4.legend(loc='lower right')\n",
        "\n",
        "\n",
        "  # Moving the legend outside the plot\n",
        "  #plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "\n",
        "  plt.savefig(\"{}{}_loss_accuracy_comparison.png\".format(data_path, model_name))  # Save the figure\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "njnUoBeFGNXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_curves_comp_with_simple(losses, accuracies, v_accuracies, v_losses, losses_sp, accuracies_sp, v_accuracies_sp, v_losses_sp, data_path):\n",
        "  #Plotting the Loss and Accuracy Curves\n",
        "\n",
        "  # Set global font size for labels\n",
        "  plt.rc('xtick', labelsize=12)    # Set x-axis label size to 12\n",
        "  plt.rc('ytick', labelsize=12)    # Set y-axis label size to 12\n",
        "  plt.rc('axes', labelsize=14)     # Set axes label size to 14\n",
        "  plt.rc('figure', titlesize=16)     # Set title size to 16\n",
        "\n",
        "  fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "  fig.suptitle('Training and Validation Loss Curve Comparison\\n between ResNet34 and Simple CNN')\n",
        "\n",
        "  y_step = 0.1\n",
        "  x_step = 2\n",
        "\n",
        "  ax1.plot(losses, label = \"Training Loss - pretrained\", color='darkblue')\n",
        "  ax1.plot(v_losses, label = \"Validation Loss - pretrained\", color='lightblue')\n",
        "  #ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('Loss')\n",
        "  # Set the y-axis limits for the first subplot\n",
        "  ax1.set_ylim(-0.1, 1.1)\n",
        "  ax1.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax1.set_xticks(range(0, 20, x_step))\n",
        "  ax1.legend()\n",
        "\n",
        "  ax2.plot(accuracies, label = \"Training Accuracy - ResNet34\", color='darkblue')\n",
        "  ax2.plot(v_accuracies, label = \"Validation Accuracy - ResNet34\", color='lightblue')\n",
        "  #ax2.set_xlabel('Epoch')\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.set_ylim(-0.1, 1.1)\n",
        "  ax2.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax2.set_xticks(range(0, 20, x_step))\n",
        "  ax2.legend(loc='lower right')\n",
        "\n",
        "  ax3.plot(losses_sp, label = \"Training Loss - Simple Model\", color='red')\n",
        "  ax3.plot(v_losses_sp, label = \"Validation Loss - Simple Model\", color='orange')\n",
        "  ax3.set_xlabel('Epoch')\n",
        "  ax3.set_ylabel('Loss')\n",
        "  # Set the y-axis limits for the first subplot\n",
        "  ax3.set_ylim(-0.1, 1.1)\n",
        "  ax3.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax3.set_xticks(range(0, 20, x_step))\n",
        "  ax3.legend()\n",
        "\n",
        "  ax4.plot(accuracies_sp, label = \"Training Accuracy - Simple Model\", color='red')\n",
        "  ax4.plot(v_accuracies_sp, label = \"Validation Accuracy - Simple Model\", color='orange')\n",
        "  ax4.set_xlabel('Epoch')\n",
        "  ax4.set_ylabel('Accuracy')\n",
        "  ax4.set_ylim(-0.1, 1.1)\n",
        "  ax4.set_yticks([i * y_step for i in range(int(1 / y_step) + 1)])\n",
        "  ax4.set_xticks(range(0, 20, x_step))\n",
        "  ax4.legend(loc='lower right')\n",
        "\n",
        "\n",
        "  # Moving the legend outside the plot\n",
        "  #plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "\n",
        "  plt.savefig(\"{}_loss_accuracy_comparison_ResNet34_vs_Simple.png\".format(data_path))  # Save the figure\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "8mUJm1YbekPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}